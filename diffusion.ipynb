{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.layers import Conv2D, Dense, LeakyReLU, BatchNormalization, UpSampling2D, Add,\\\n",
    "    AveragePooling2D, Concatenate, Input, Lambda, Activation, LayerNormalization\n",
    "from tensorflow.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 64\n",
    "N_BLOCK = 2\n",
    "EPOCHS = 100\n",
    "CURRENT_EPOCH = 1\n",
    "SAVE_EVERY_N_EPOCH = 5\n",
    "\n",
    "LOG_DIR = './results/logs/'\n",
    "CKPT_DIR = './results/models_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data_path = pathlib.Path('/kaggle/input/another-anime-face-dataset/animefaces256cleaner')\n",
    "file_list = [str(path) for path in inp_data_path.glob('*.jpg')]\n",
    "\n",
    "def preprocess(file_path, img_size=IMG_SIZE):\n",
    "    imgs = tf.io.read_file(file_path)\n",
    "    imgs = tf.io.decode_jpeg(imgs, channels=3)\n",
    "    imgs = tf.image.resize(imgs, [img_size, img_size])\n",
    "\n",
    "    imgs = tf.image.convert_image_dtype(imgs, dtype=tf.float32)\n",
    "    imgs = (imgs - 127.5) / 127.5\n",
    "    return imgs\n",
    "\n",
    "\n",
    "data_path = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "train_data = data_path.map(preprocess).shuffle(500).batch(BATCH_SIZE)\n",
    "test_data = data_path.map(preprocess).shuffle(500).batch(16)\n",
    "\n",
    "img = next(iter(train_data))\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1000\n",
    "\n",
    "# create a fixed beta schedule\n",
    "beta = np.linspace(0.0001, 0.02, timesteps)\n",
    "\n",
    "# this will be used as discussed in the reparameterization trick\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[:-1]), axis=0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1-alpha_bar)\n",
    "\n",
    "\n",
    "def add_noise(x_0, t):\n",
    "    noise = np.random.normal(size=x_0.shape)\n",
    "    sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), [-1, 1, 1, 1])\n",
    "    one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), [-1, 1, 1, 1])\n",
    "    noisy_img = sqrt_alpha_bar_t  * x_0 + one_minus_sqrt_alpha_bar_t  * noise\n",
    "    return noisy_img, noise\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 30))\n",
    "\n",
    "for index, i in enumerate([10, 100, 300, 600]):\n",
    "    noisy_im, noise = add_noise(img[0], np.array([i,]))\n",
    "    noisy_im = np.squeeze(noisy_im)\n",
    "    plt.subplot(1, 4, index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(noisy_im)\n",
    "\n",
    "plt.savefig('image.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = Conv2D(filters=self.hidden_dim * 3, kernel_size=1, strides=1, use_bias=False)\n",
    "\n",
    "        self.to_out = Sequential([\n",
    "            Conv2D(filters=dim, kernel_size=1, strides=1),\n",
    "            LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        residual = x\n",
    "        b, h, w, c = x.shape\n",
    "        \n",
    "        qkv = self.to_qkv(x)\n",
    "        q, k, v = tf.split(qkv, num_or_size_splits=3, axis=-1)\n",
    "        \n",
    "        q = tf.reshape(q, [-1, self.heads, self.dim_head, h*w])\n",
    "        k = tf.reshape(k, [-1, self.heads, self.dim_head, h*w])\n",
    "        v = tf.reshape(v, [-1, self.heads, self.dim_head, h*w])\n",
    "        \n",
    "        q = tf.nn.softmax(q, axis=-2)\n",
    "        k = tf.nn.softmax(k, axis=-1)\n",
    "        q = q * self.scale\n",
    "        context = tf.einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = tf.einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = tf.reshape(out, [-1, h, w, self.hidden_dim])\n",
    "        out = self.to_out(out, training=training)\n",
    "\n",
    "        return out + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlock(inp, filter, t):\n",
    "    if inp.shape[-1] == filter:\n",
    "        residual = inp\n",
    "    else:\n",
    "        residual = Conv2D(filter,  1, 1, padding='same')(inp)\n",
    "    \n",
    "    x = Conv2D(filter, 3, 1, padding='same')(inp)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = tfa.layers.GroupNormalization(8, epsilon=1e-05)(x)\n",
    "    # It is common to use group norm in the literature\n",
    "    \n",
    "    t = Dense(filter*2)(t)\n",
    "    gamma, beta= tf.split(t, num_or_size_splits=2, axis=-1)\n",
    "    x = x * (gamma + 1) + beta\n",
    "    x = Activation('swish')(x)\n",
    "    \n",
    "    x = Conv2D(filter, 3, 1, padding='same')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = tfa.layers.GroupNormalization(8, epsilon=1e-05)(x)\n",
    "    x = Activation('swish')(x)\n",
    "    out = Add()([x, residual])\n",
    "    return out\n",
    "\n",
    "def downBlock(x, skips, filter, n_block, t):\n",
    "    for _ in range(n_block):\n",
    "        x = resBlock(x, filter, t)\n",
    "        skips.append(x)\n",
    "        \n",
    "    # adding the attention layer will have better global coherence\n",
    "    x = LinearAttention(filter)(x) \n",
    "    out = AveragePooling2D()(x)\n",
    "    return out\n",
    "    \n",
    "def upBlock(x, skips, filter, n_block, t):\n",
    "    x = UpSampling2D()(x)\n",
    "    for _ in range(n_block):\n",
    "        x = Concatenate()([x, skips.pop()])\n",
    "        x = resBlock(x, filter, t)\n",
    "        \n",
    "    x = LinearAttention(filter)(x)\n",
    "    return x\n",
    "\n",
    "# time embedding for the discrete time schedule\n",
    "class SinusoidalPosEmb(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=32, max_positions=10000):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.max_positions = max_positions\n",
    "        self.dense1 = Dense(self.dim, activation='swish')\n",
    "        self.dense2 = Dense(self.dim, activation='swish')\n",
    "        \n",
    "    def call(self, x, training=True):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.max_positions) / (half_dim - 1)\n",
    "        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
    "        emb = x * emb[None, :]\n",
    "\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        emb = tf.reshape(emb, [-1, 1, 1, self.dim])\n",
    "        emb = self.dense1(emb)\n",
    "        emb = self.dense2(emb)\n",
    "        return emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_NET(img_size):\n",
    "    noisy_img = Input(img_size)\n",
    "    time = Input((1,))\n",
    "    \n",
    "    e = SinusoidalPosEmb()(time)\n",
    "    x = Conv2D(32, 1, 1, padding='same')(noisy_img)\n",
    "    skips = []\n",
    "    \n",
    "    x = downBlock(x, skips, 64, N_BLOCK, e)\n",
    "    x = downBlock(x, skips, 128, N_BLOCK, e)\n",
    "    x = downBlock(x, skips, 128, N_BLOCK, e)\n",
    "\n",
    "    for _ in range(N_BLOCK):\n",
    "        x = resBlock(x, 256, e)\n",
    "        \n",
    "    x = upBlock(x, skips, 128, N_BLOCK, e)\n",
    "    x = upBlock(x, skips, 128, N_BLOCK, e)\n",
    "    x = upBlock(x, skips, 64, N_BLOCK, e)\n",
    "    x = resBlock(x, 32, e)\n",
    "    \n",
    "    out = Conv2D(3, 1, 1, padding='same', kernel_initializer=\"zeros\")(x)\n",
    "    return Model([noisy_img, time], out)\n",
    "\n",
    "u_net = U_NET((64, 64, 3))\n",
    "#u_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "ckpt = tf.train.Checkpoint(u_net=u_net)                          \n",
    "# save model\n",
    "\n",
    "summary_Writer = tf.summary.create_file_writer(LOG_DIR)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, CKPT_DIR, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH + 1\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = r'./models/git_out'\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.mkdir(OUTPUT_PATH)\n",
    "\n",
    "def ddim(x_t, pred_noise, t, step_size):\n",
    "    alpha_t_bar = np.reshape(np.take(alpha_bar, t), [-1, 1, 1, 1])\n",
    "    alpha_t_minus_one = np.reshape(np.take(alpha_bar, t-step_size), [-1, 1, 1, 1])\n",
    "        \n",
    "    pred = (x_t - ((1 - alpha_t_bar) ** 0.5) * pred_noise)/ (alpha_t_bar ** 0.5)\n",
    "    pred = (alpha_t_minus_one ** 0.5) * pred\n",
    "\n",
    "    pred = pred + ((1 - alpha_t_minus_one) ** 0.5) * pred_noise\n",
    "    return pred\n",
    "\n",
    "inference_timesteps = 200\n",
    "inference_range = range(0, timesteps, timesteps // inference_timesteps)\n",
    "inf_step = timesteps // inference_timesteps\n",
    "\n",
    "def generate_save_img(epoch, path=OUTPUT_PATH, save=True):\n",
    "    x = tf.random.normal((16,64,64,3))\n",
    "    for index, i in enumerate(reversed(range(inference_timesteps))):\n",
    "        t = np.repeat(inference_range[i], 16)\n",
    "        \n",
    "        pred_noise = u_net([x, t])\n",
    "        x = ddim(x, pred_noise, t, inf_step)\n",
    "        \n",
    "        if any(t-inf_step) == 0:\n",
    "            break\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        axs = plt.subplot(4, 4, i+1)\n",
    "        axs.imshow(x[i] * 0.5 + 0.5)\n",
    "        plt.axis('off') \n",
    "\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(path, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp_img):\n",
    "    t_size = inp_img.shape[0]\n",
    "    t = tf.random.uniform(shape=[t_size,], minval=0, maxval=timesteps, dtype=tf.int32)\n",
    "    noisy_img, noise = add_noise(inp_img, t)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pre_noise = u_net([noisy_img, t])\n",
    "        loss = loss_fn(pre_noise, noise)\n",
    "    \n",
    "    gradients = tape.gradient(loss, u_net.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, u_net.trainable_variables))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(CURRENT_EPOCH, EPOCHS+1):\n",
    "\n",
    "    start = time.time()\n",
    "    print('Start of epoch {}'.format(epoch))\n",
    "    \n",
    "    losses = []\n",
    "    for step, data in enumerate(train_data):\n",
    "\n",
    "        loss = train_step(data)\n",
    "        losses.append(loss)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "        if step > 1000:\n",
    "            break\n",
    "\n",
    "    \n",
    "    print('\\n Epoch {} finished ~ ~ ~ ~ ~'.format(epoch))\n",
    "    with summary_Writer.as_default():\n",
    "        tf.summary.scalar('loss', np.mean(losses), step=epoch)\n",
    "\n",
    "    if epoch % SAVE_EVERY_N_EPOCH == 0:\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        #save model\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch, ckpt_save_path))\n",
    "    \n",
    "    print ('epoch {} loss is {} \\n'.format(epoch,np.mean(losses))) \n",
    "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch,time.time()-start))                                             \n",
    "    generate_save_img(epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96740db8853225a28343985eb2afde8386a2ceb81d2b3b54d41408b8c491d78e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
